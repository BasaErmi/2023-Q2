## 模式识别作业一

|   学号   |  姓名  |
| :------: | :----: |
| 20319045 | 刘冠麟 |

### 实验目的

1. 熟悉 Harris 角点检测器的原理和基本使用
2. 熟悉 RANSAC 抽样一致方法的使用场景
3. 熟悉 HOG 描述子的基本原理

### 实验要求

1. 提交实验报告，要求有适当步骤说明和结果分析，对比
2. 将代码和结果打包提交
3. 实验可以使用现有的特征描述子实现

### 实验内容

1. 使用 Harris 焦点检测器寻找关键点。
2. 构建描述算子来描述图中的每个关键点，比较两幅图像的两组描述子，并进行匹配。
3. 根据一组匹配关键点，使用 RANSAC 进行仿射变换矩阵的计算。
4. 将第二幅图变换过来并覆盖在第一幅图上，拼接形成一个全景图像。
5. 实现不同的描述子，并得到不同的拼接结果。

### 实验过程

### Harris角点算法

#### 算法原理

Harris角点检测算法基本思想是使用一个固定窗口在图像上进行任意方向上的滑动，比较滑动前与滑动后两种情况窗口中的像素灰度变化程度，如果存在任意方向上的滑动，都有着较大灰度变化，那么我们可以认为该窗口中存在角点。

根据Harris的算法基本思想可以直接得到其数学描述：
$$
E(u,v) = \sum_{x,y} w(x,y) [I(x+u,y+v)-I(x,y)]^2
$$
其中$E(u,v)$为能量函数，u v体现窗口的移动；$w(x,y)$为每个像素值上的权重，体现对整体的贡献度，一般选用高斯滤波核。$I(x+u,y+v)-I(x,y)$为角点移动前后的灰度差。

对$I(x+u,y+v)$进行泰勒展开，可以得到
$$
I(x+u,y+v) = I(x,y) +uI_x + vI_y
$$
其中$I_x,I_y$为在x,y处像素点在x和y方向上的梯度。

带入$E(u,v)$中可以得到：
$$
E(u,v) = \sum_{x,y} w(x,y) (uI_x + vI_y)^2\\=w(x,y)\sum_{x,y}  (u^2I_x^2 + uvI_xI_y + v^2I_y^2)
$$
写成矩阵形式：
$$
E(u,v)=[u, v] \cdot w(x, y)\sum_{x, y} \begin{bmatrix} I_x^2 & I_x I_y \\ I_x I_y & I_y^2 \end{bmatrix} \cdot \begin{bmatrix} u \\ v \end{bmatrix}
$$
令
$$
M=w(x, y)\sum_{x, y} \begin{bmatrix} I_x^2 & I_x I_y \\ I_x I_y & I_y^2 \end{bmatrix}
$$
可以得到：
$$
\\A=w(x, y)\sum_{x,y}I_x^2,\\B=w(x, y)\sum_{x,y}I_xI_y,\\C=w(x, y)\sum_{x,y}I_y^2
$$
可以通过计算矩阵$M$的行列式以及迹来计算响应函数$R$
$$
\text{det}M=AC-B^2\\
\text{trace}M=A+C\\
R=\text{det}M-k(\text{trace}M)^2
$$
其中k为常数。对于所有像素点的角点响应函数在局部邻域内选取具有最大角点响应值的像素作为候选角点。

最后再对候选角点进行阈值化筛选，即可得到图像的角点。

#### 算法实现

对应算法原理中的步骤，可以用python配合opencv库实现对应算法：

首先对图像进行灰度处理：

```python
# 灰度化图像
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
gray = np.float32(gray)
```

然后计算$I_x，I_y$：

```python
# 计算x和y方向的梯度
grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=ksize)
grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=ksize)
```

由原理中的公式，可以直接通过$I_x,I_y$计算得到计算R所需的$A,B,C$。

其中权重$w(x,y)$在本次实验中选择用高斯滤波器实现：

```python
# 计算梯度的乘积和平方
Ixx = grad_x ** 2
Ixy = grad_x * grad_y
Iyy = grad_y ** 2

# 乘上权重
A = cv2.GaussianBlur(Ixx, (block_size, block_size), 0)
B = cv2.GaussianBlur(Ixy, (block_size, block_size), 0)
C = cv2.GaussianBlur(Iyy, (block_size, block_size), 0)
```

最后再利用得到的A、B、C计算矩阵M的行列式和迹，最终得到响应reponse

```python
# Harris角点响应
det = A * C - B ** 2
trace = A + C
response = det - k * trace ** 2
```

然后再对得到的候选角点进行阈值化，其中阈值由调用函数时传入参数所决定：

```python
# 阈值化
corners = response > threshold * response.max()
corners = np.array(corners, dtype=np.uint8)
```

将代码封装进函数`harris_corners`中，使用opencv库读取图像并应用函数进行角点检测，并保存。

```python
# 读取图像
image = cv2.imread('images/sudoku.png')

# 应用Harris角点检测
result_image = harris_corners(image, block_size=3, ksize=3, k=0.04, threshold=0.01)
# 显示结果
plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))
plt.show()
# 保存结果
cv2.imwrite('results/sudoku_keypoints.jpg', result_image)
```

#### 实验结果

实验结果如下，图片保存在results/目录下，命名为 sudoku_keypoints.png。

![image-20240507181612062](./assets/image-20240507181612062.png)

### 关键点描述与匹配

使用实现的 Harris 角点检测算法提取` images/uttower1.jpg `和 `images/uttower2.jpg` 的关键点，并将提取的关键点检测结果保存到` results/`目录下，命名为 `uttower1_keypoints.jpg` 和 `uttower2_keypoints.jpg`:

结果如下：

![uttower1_keypoints](./assets/uttower1_keypoints.jpg)

![uttower2_keypoints](./assets/uttower2_keypoints.jpg)

#### 使用SIFT进行特征描述

SIFT（尺度不变特征变换）是一种用于计算图像局部特征的算法。SIFT算法通过检测图像中的关键点，并为每个关键点计算描述其局部特征的向量，这些特征向量具有尺度不变性和旋转不变性。SIFT算法的主要步骤包括：

1. **尺度空间极值检测**：通过在图像的高斯金字塔上应用尺度空间拉普拉斯算子来实现在不同尺度和位置上检测图像中的极值点（关键点）。通过对图像进行高斯模糊处理并不断减小模糊程度，得到一系列尺度空间的图像。然后对每个像素点在尺度空间中的相邻像素进行比较，找到局部极值点，这些点被认为是图像中的关键点。
2. **关键点定位**：对于检测到的极值点通过在尺度空间和图像中的梯度信息计算其准确位置和尺度。
3. **方向分配**：通过在关键点周围的图像区域内计算梯度方向直方图来实现对每个关键点分配一个或多个主要方向。梯度方向直方图的峰值即为主要方向，可以通过插值来提高精度。
4. **描述子生成**：在每个关键点周围的图像区域内以关键点为中心，在确定的尺度和方向上构建一个局部块。然后在这个局部块中计算图像梯度的方向和幅度，并将其转换为一个局部特征向量
5. **描述子匹配**：使用描述子匹配算法（本实验中使用**最近邻算法knn**）来比较不同图像中的关键点描述子，并找到最佳匹配。一般通过计算描述子之间的距离（本实验中按照题目要求使用**欧氏距离**）来度量它们之间的相似性。

在本次实验中使用opencv库中关于SIFT的配套API来完成对于图像的SIFT特征描述。

##### SIFT处理步骤